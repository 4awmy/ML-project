{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6e5b7-13b9-420b-81d4-0ade0ca7c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paste the path inside the quotes\n",
    "# It usually looks like '/content/your_file.csv'\n",
    "df = pd.read_csv(r\"E:\\College\\Term 5\\AI\\Dataset\\AI_Project\\data.csv\")\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea566bcd-ea39-4247-a2c7-63ede95dc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Check for missing values\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# 2. Summary Statistics (Average salary, max risk, etc.)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# 3. Visualize the Automation Risk\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['Automation Risk (%)'], bins=20, kde=True)\n",
    "plt.title('Distribution of Automation Risk')\n",
    "plt.xlabel('Automation Risk (%)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b009384-d223-4097-992d-0c7fdbc0671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Human_Need'\n",
    "# 1 = Safe (Human is needed)\n",
    "# 0 = At Risk (Machine will replace)\n",
    "\n",
    "def classify_risk(risk):\n",
    "    if risk < 50:\n",
    "        return 1  # High Human Need\n",
    "    else:\n",
    "        return 0  # Low Human Need\n",
    "\n",
    "# Apply this rule to the data\n",
    "df['Human_Need'] = df['Automation Risk (%)'].apply(classify_risk)\n",
    "\n",
    "print(\"Target Column 'Human_Need' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84239d14-e8ee-44db-91bc-f41f4e5eefd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# List of columns that are currently text\n",
    "text_cols = ['Job Title', 'Industry', 'Required Education', 'Location', 'Job Status', 'AI Impact Level']\n",
    "\n",
    "# Convert them\n",
    "for col in text_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "print(\"All text converted to numbers. Here is the final table:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185650a2-a75a-4c5f-8947-3660c4187790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Define Features (X) and Target (y)\n",
    "# We DROP 'Automation Risk (%)' because that gives away the answer!\n",
    "# We DROP 'Human_Need' because that is what we are predicting.\n",
    "X = df.drop(columns=['Automation Risk (%)', 'Human_Need'])\n",
    "y = df['Human_Need']\n",
    "\n",
    "# 2. Split the data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Initialize the 3 Models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# 4. Train and Evaluate\n",
    "print(\"Model Results:\\n\" + \"-\"*30)\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    print(f\"{name} Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f87a0-b5e7-4cf2-88fd-0b4e3483e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdbda5-64f0-4baf-85c3-aff6dc71feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ==========================================\n",
    "# PASTE YOUR PATH BELOW (Keep the r before the quotes!)\n",
    "# Example: file_path = r\"E:\\College\\Term 5\\AI\\Dataset\\AI_Project\\data.csv\"\n",
    "# ==========================================\n",
    "file_path = r\"E:\\College\\Term 5\\AI\\Dataset\\AI_Project\\data.csv\"\n",
    "# ^^^ DELETE \"PASTE_YOUR_PATH_HERE\" AND PASTE (Ctrl+V) \n",
    "\n",
    "\n",
    "# --- APP SETUP ---\n",
    "st.title(\"ðŸ¤– Job Automation Predictor\")\n",
    "\n",
    "@st.cache_data\n",
    "def get_model():\n",
    "    try:\n",
    "        # Load the file using the specific path\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    except OSError:\n",
    "        # This handles if the path includes quotes inside the string\n",
    "        try:\n",
    "            clean_path = file_path.replace('\"', '')\n",
    "            df = pd.read_csv(clean_path)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # Preprocessing\n",
    "    le = LabelEncoder()\n",
    "    cols = ['Job Title', 'Industry', 'Required Education', 'Location', 'Job Status', 'AI Impact Level']\n",
    "    for col in cols:\n",
    "        if col in df.columns: df[col] = le.fit_transform(df[col])\n",
    "            \n",
    "    df['Human_Need'] = df['Automation Risk (%)'].apply(lambda x: 1 if x < 50 else 0)\n",
    "    X = df[['Median Salary (USD)', 'Remote Work Ratio (%)', 'AI Impact Level', 'Experience Required (Years)']]\n",
    "    y = df['Human_Need']\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# --- INPUTS & PREDICTION ---\n",
    "st.sidebar.header(\"Job Features\")\n",
    "salary = st.sidebar.slider(\"Median Salary ($)\", 30000, 150000, 80000)\n",
    "remote = st.sidebar.slider(\"Remote Work Ratio (%)\", 0, 100, 50)\n",
    "ai = st.sidebar.selectbox(\"AI Impact Level (1=Low, 5=High)\", [1, 2, 3, 4, 5])\n",
    "exp = st.sidebar.slider(\"Years of Experience\", 0, 20, 5)\n",
    "\n",
    "if model is None:\n",
    "    st.error(f\"ðŸš¨ ERROR: Cannot find the file at this path:\\n\\n{file_path}\\n\\nPlease check the path in your code.\")\n",
    "elif st.button(\"Predict\"):\n",
    "    prediction = model.predict([[salary, remote, ai, exp]])\n",
    "    if prediction[0] == 1: st.success(\"âœ… SAFE: High Human Need\")\n",
    "    else: st.error(\"âš ï¸ RISK: Likely Automated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
